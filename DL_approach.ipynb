{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxwKnWrK73cV"
      },
      "source": [
        "#Pip installs, imports, data extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsSKSsuxe-DJ",
        "outputId": "696ebeca-826f-4b43-93fc-61c4695673ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▎                            | 10 kB 25.8 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 30 kB 15.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 51 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 61 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 71 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 81 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 92 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 100 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.1.0)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.21.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-21.10.1 scikit-optimize-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-optimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1J-4e94o1jY",
        "outputId": "fb32368c-9d0f-49b5-bee7-6464eb48288e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (2.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHqTvZn1oVYa"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ud0xBQlpHsK",
        "outputId": "14597265-795c-4f36-8ec2-0cebc4b25dec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1m8vWr3w50vqEY88DC8cVKPuMMq1z791E\n",
            "To: /content/kaggle.json\n",
            "100% 69.0/69.0 [00:00<00:00, 140kB/s]\n"
          ]
        }
      ],
      "source": [
        "# download kaggle API credentials from drive\n",
        "!gdown --id 1m8vWr3w50vqEY88DC8cVKPuMMq1z791E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAAICc5PJc2F"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYHWeEYzobD2",
        "outputId": "3d1480af-c50c-4381-9903-01d4324cfcfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading competitive-data-science-predict-future-sales.zip to /content\n",
            "\r  0% 0.00/15.1M [00:00<?, ?B/s]\r 33% 5.00M/15.1M [00:00<00:00, 48.1MB/s]\n",
            "\r100% 15.1M/15.1M [00:00<00:00, 88.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c competitive-data-science-predict-future-sales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opYoAFi9KITz",
        "outputId": "83859ed7-73b7-4787-c921-0163397cfd10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/competitive-data-science-predict-future-sales.zip\n",
            "  inflating: /content/kaggle_data/item_categories.csv  \n",
            "  inflating: /content/kaggle_data/items.csv  \n",
            "  inflating: /content/kaggle_data/sales_train.csv  \n",
            "  inflating: /content/kaggle_data/sample_submission.csv  \n",
            "  inflating: /content/kaggle_data/shops.csv  \n",
            "  inflating: /content/kaggle_data/test.csv  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/competitive-data-science-predict-future-sales.zip -d /content/kaggle_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4ghkR7RoCMV"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import pickle\n",
        "from xgboost import XGBRegressor, DMatrix\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import make_scorer\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.callbacks import DeadlineStopper, DeltaYStopper\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "from matplotlib.pylab import rcParams\n",
        "import pprint\n",
        "from functools import partial\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "from itertools import product\n",
        "import time\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import callbacks\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Conv1D, MaxPooling1D, TimeDistributed, Flatten\n",
        "import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pdb\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYzM0EaK7vRR"
      },
      "source": [
        "#Preprocessing and feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5JTuGAXwPmd",
        "outputId": "35afbced-c9bd-4735-b304-a89aa447309e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:102: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:103: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:106: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:107: FutureWarning: The default value of regex will change from True to False in a future version.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting matrix construction...\n",
            "Matrix effectively produced in 16.72688126564026 seconds\n"
          ]
        }
      ],
      "source": [
        "def name_correction(x):\n",
        "    x = x.lower() # all letters lower case\n",
        "    x = x.partition('[')[0] # partition by square brackets\n",
        "    x = x.partition('(')[0] # partition by curly brackets\n",
        "    x = re.sub('[^A-Za-z0-9А-Яа-я]+', ' ', x) # remove special characters\n",
        "    x = x.replace('  ', ' ') # replace double spaces with single spaces\n",
        "    x = x.strip() # remove leading and trailing white space\n",
        "    return x\n",
        "\n",
        "train_path = '/content/kaggle_data/sales_train.csv'\n",
        "test_path = '/content/kaggle_data/test.csv'\n",
        "items_path = '/content/kaggle_data/items.csv'\n",
        "shop_path = '/content/kaggle_data/shops.csv'\n",
        "categories_path = '/content/kaggle_data/item_categories.csv'\n",
        "submission_path = '/content/kaggle_data/sample_submission.csv'\n",
        "\n",
        "train = pd.read_csv(train_path)\n",
        "test = pd.read_csv(test_path)\n",
        "items = pd.read_csv(items_path)\n",
        "shops = pd.read_csv(shop_path)\n",
        "cats = pd.read_csv(categories_path)\n",
        "submission = pd.read_csv(submission_path)\n",
        "\n",
        "#Outliers Removing\n",
        "\n",
        "'''\n",
        "* Removes big outliers\n",
        "* Remove rows where price is negative\n",
        "* Makes Values < 1 = 0\n",
        "'''\n",
        "train = train[(train.item_price < 300000 )& (train.item_cnt_day < 1000)]\n",
        "train = train[train.item_price > 0].reset_index(drop = True)\n",
        "train.loc[train.item_cnt_day < 1, \"item_cnt_day\"] = 0\n",
        "\n",
        "#Edit shop duplicates\n",
        "\n",
        "#Якутск Орджоникидзе, 56\n",
        "train.loc[train.shop_id == 0, 'shop_id'] = 57\n",
        "test.loc[test.shop_id == 0, 'shop_id'] = 57\n",
        "#Якутск ТЦ \"Центральный\"\n",
        "train.loc[train.shop_id == 1, 'shop_id'] = 58\n",
        "test.loc[test.shop_id == 1, 'shop_id'] = 58\n",
        "#Жуковский ул. Чкалова 39м²\n",
        "train.loc[train.shop_id == 10, 'shop_id'] = 11\n",
        "test.loc[test.shop_id == 10, 'shop_id'] = 11\n",
        "\n",
        "#Add city and category to shop\n",
        "shops.loc[shops.shop_name == 'Сергиев Посад ТЦ \"7Я\"',\"shop_name\" ] = 'СергиевПосад ТЦ \"7Я\"'\n",
        "shops[\"city\"] = shops.shop_name.str.split(\" \").map( lambda x: x[0] )\n",
        "shops[\"category\"] = shops.shop_name.str.split(\" \").map( lambda x: x[1] )\n",
        "shops.loc[shops.city == \"!Якутск\", \"city\"] = \"Якутск\"\n",
        "\n",
        "#first\n",
        "#pdb.set_trace() #type in \" continue \" to escape and continue running the code\n",
        "\n",
        "\n",
        "#Only keep shop category >= 5 shops otherwise = other\n",
        "category = []\n",
        "for cat in shops.category.unique():\n",
        "    if len(shops[shops.category == cat]) >= 5:\n",
        "        category.append(cat)\n",
        "shops.category = shops.category.apply( lambda x: x if (x in category) else \"other\" )\n",
        "\n",
        "#Label Encode shops\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "shops[\"shop_category\"] = LabelEncoder().fit_transform(shops.category)\n",
        "shops[\"shop_city\"] = LabelEncoder().fit_transform(shops.city)\n",
        "shops = shops[[\"shop_id\", \"shop_category\", \"shop_city\"]]\n",
        "\n",
        "#second\n",
        "#pdb.set_trace() #type in \" continue \" to escape and continue running the code\n",
        "\n",
        "#Cleaning Categorical Data\n",
        "cats[\"type_code\"] = cats.item_category_name.apply( lambda x: x.split(\" \")[0] ).astype(str)\n",
        "cats.loc[ (cats.type_code == \"Игровые\")| (cats.type_code == \"Аксессуары\"), \"category\" ] = \"Игры\"\n",
        "\n",
        "#Only keep categories >= 5 shops otherwise = other\n",
        "category = []\n",
        "for cat in cats.type_code.unique():\n",
        "    if len(cats[cats.type_code == cat]) >= 5: \n",
        "        category.append( cat )\n",
        "cats.type_code = cats.type_code.apply(lambda x: x if (x in category) else \"etc\")\n",
        "\n",
        "#Label Encode categories\n",
        "cats.type_code = LabelEncoder().fit_transform(cats.type_code)\n",
        "cats[\"split\"] = cats.item_category_name.apply(lambda x: x.split(\"-\"))\n",
        "cats[\"subtype\"] = cats.split.apply(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\n",
        "cats[\"subtype_code\"] = LabelEncoder().fit_transform( cats[\"subtype\"] )\n",
        "cats = cats[[\"item_category_id\", \"subtype_code\", \"type_code\"]]\n",
        "\n",
        "#Split item names by first bracket\n",
        "items[\"name1\"], items[\"name2\"] = items.item_name.str.split(\"[\", 1).str\n",
        "items[\"name1\"], items[\"name3\"] = items.item_name.str.split(\"(\", 1).str\n",
        "\n",
        "#Replace special characters and turn to lower case\n",
        "items[\"name2\"] = items.name2.str.replace('[^A-Za-z0-9А-Яа-я]+', \" \").str.lower()\n",
        "items[\"name3\"] = items.name3.str.replace('[^A-Za-z0-9А-Яа-я]+', \" \").str.lower()\n",
        "\n",
        "#Fill nulls with '0'\n",
        "items = items.fillna('0')\n",
        "\n",
        "items[\"item_name\"] = items[\"item_name\"].apply(lambda x: name_correction(x))\n",
        "\n",
        "#Return all characters except the last if name 2 is not \"0\" - the closing bracket\n",
        "items.name2 = items.name2.apply( lambda x: x[:-1] if x !=\"0\" else \"0\")\n",
        "\n",
        "#Clean item type\n",
        "items[\"type\"] = items.name2.apply(lambda x: x[0:8] if x.split(\" \")[0] == \"xbox\" else x.split(\" \")[0])\n",
        "items.loc[(items.type == \"x360\") | (items.type == \"xbox360\") | (items.type == \"xbox 360\") ,\"type\"] = \"xbox 360\"\n",
        "items.loc[ items.type == \"\", \"type\"] = \"mac\"\n",
        "items.type = items.type.apply(lambda x: x.replace(\" \", \"\") )\n",
        "items.loc[(items.type == 'pc' ) | (items.type == 'pс') | (items.type == \"pc\"), \"type\" ] = \"pc\"\n",
        "items.loc[items.type == 'рs3' , \"type\"] = \"ps3\"\n",
        "\n",
        "#Group by type and count items, replace with others items with count less than 40\n",
        "group_sum = items.groupby([\"type\"]).agg({\"item_id\": \"count\"})\n",
        "group_sum = group_sum.reset_index()\n",
        "drop_cols = []\n",
        "for cat in group_sum.type.unique():\n",
        "    if group_sum.loc[(group_sum.type == cat), \"item_id\"].values[0] < 40:\n",
        "        drop_cols.append(cat)\n",
        "items.name2 = items.name2.apply(lambda x: \"other\" if (x in drop_cols) else x)\n",
        "items = items.drop([\"type\"], axis = 1)\n",
        "\n",
        "#Label Encode items names\n",
        "items.name2 = LabelEncoder().fit_transform(items.name2)\n",
        "items.name3 = LabelEncoder().fit_transform(items.name3)\n",
        "\n",
        "items.drop([\"item_name\", \"name1\"],axis = 1, inplace= True)\n",
        "\n",
        "'''\n",
        "Create a matrix with every combination of month, shop, and item to increase months.\n",
        "Item_cnt_day is then summed into an item_cnt_month\n",
        "'''\n",
        "ts = time.time()\n",
        "print('Starting matrix construction...')\n",
        "matrix = []\n",
        "cols  = [\"date_block_num\", \"shop_id\", \"item_id\"]\n",
        "for i in range(34):\n",
        "    sales = train[train.date_block_num == i]\n",
        "    matrix.append(np.array(list(product([i], sales.shop_id.unique(), sales.item_id.unique())), dtype = np.int16) )\n",
        "\n",
        "matrix = pd.DataFrame(np.vstack(matrix), columns = cols )\n",
        "matrix[\"date_block_num\"] = matrix[\"date_block_num\"].astype(np.int8)\n",
        "matrix[\"shop_id\"] = matrix[\"shop_id\"].astype(np.int8)\n",
        "matrix[\"item_id\"] = matrix[\"item_id\"].astype(np.int16)\n",
        "matrix.sort_values(cols, inplace = True )\n",
        "print(f'Matrix effectively produced in {time.time()- ts} seconds')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuqdGQ0PYPT5",
        "outputId": "1bc01392-eff2-4db5-c474-ba52671c30a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "item_cnt_month\n",
            "date_avg_item_cnt\n",
            "date_item_avg_item_cnt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:89: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "date_shop_avg_item_cnt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:100: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "date_shop_item_avg_item_cnt\n",
            "date_shop_subtype_avg_item_cnt\n",
            "date_city_avg_item_cnt\n",
            "date_item_city_avg_item_cnt\n",
            "date_item_avg_item_price\n",
            "delta_revenue\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1.5347578525543213"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Add revenue to train df\n",
        "train[\"revenue\"] = train[\"item_cnt_day\"] * train[\"item_price\"]\n",
        "\n",
        "ts = time.time()\n",
        "group = train.groupby( [\"date_block_num\", \"shop_id\", \"item_id\"] ).agg( {\"item_cnt_day\": [\"sum\"]} )\n",
        "group.columns = [\"item_cnt_month\"]\n",
        "group.reset_index( inplace = True)\n",
        "matrix = pd.merge( matrix, group, on = cols, how = \"left\" )\n",
        "matrix[\"item_cnt_month\"] = matrix[\"item_cnt_month\"].fillna(0).astype(np.float16)\n",
        "time.time() - ts\n",
        "\n",
        "#Create a test set for month 34.\n",
        "test[\"date_block_num\"] = 34\n",
        "test[\"date_block_num\"] = test[\"date_block_num\"].astype(np.int8)\n",
        "test[\"shop_id\"] = test.shop_id.astype(np.int8)\n",
        "test[\"item_id\"] = test.item_id.astype(np.int16)\n",
        "\n",
        "ts = time.time()\n",
        "\n",
        "#Concatenate train and test sets.\n",
        "matrix = pd.concat([matrix, test.drop([\"ID\"],axis = 1)], ignore_index=True, sort=False, keys=cols)\n",
        "matrix.fillna(0, inplace = True)\n",
        "time.time() - ts\n",
        "\n",
        "#Add shop, items and categories data onto matrix df.\n",
        "ts = time.time()\n",
        "matrix = pd.merge( matrix, shops, on = [\"shop_id\"], how = \"left\" )\n",
        "matrix = pd.merge( matrix, items, on = [\"item_id\"], how = \"left\" )\n",
        "matrix = pd.merge( matrix, cats, on = [\"item_category_id\"], how = \"left\" )\n",
        "matrix[\"shop_city\"] = matrix[\"shop_city\"].astype(np.int8)\n",
        "matrix[\"shop_category\"] = matrix[\"shop_category\"].astype(np.int8)\n",
        "matrix[\"item_category_id\"] = matrix[\"item_category_id\"].astype(np.int8)\n",
        "matrix[\"subtype_code\"] = matrix[\"subtype_code\"].astype(np.int8)\n",
        "matrix[\"name2\"] = matrix[\"name2\"].astype(np.int8)\n",
        "matrix[\"name3\"] = matrix[\"name3\"].astype(np.int16)\n",
        "matrix[\"type_code\"] = matrix[\"type_code\"].astype(np.int8)\n",
        "time.time() - ts\n",
        "\n",
        "# Define a lag feature function\n",
        "def lag_feature( df,lags, cols ):\n",
        "  for col in cols:\n",
        "      print(col)\n",
        "      tmp = df[[\"date_block_num\", \"shop_id\",\"item_id\",col ]]\n",
        "      for i in lags:\n",
        "          shifted = tmp.copy()\n",
        "          shifted.columns = [\"date_block_num\", \"shop_id\", \"item_id\", col + \"_lag_\"+str(i)]\n",
        "          shifted.date_block_num = shifted.date_block_num + i\n",
        "          df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n",
        "  return df\n",
        "\n",
        "#Add item_cnt_month lag features.\n",
        "ts = time.time()\n",
        "matrix = lag_feature( matrix, [1,2,3], [\"item_cnt_month\"] )\n",
        "time.time() - ts\n",
        "\n",
        "#Add the previous month's average item_cnt.\n",
        "ts = time.time()\n",
        "group = matrix.groupby( [\"date_block_num\"] ).agg({\"item_cnt_month\" : [\"mean\"]})\n",
        "group.columns = [\"date_avg_item_cnt\"]\n",
        "group.reset_index(inplace = True)\n",
        "\n",
        "#Add lag values of item_cnt_month for month / item_id.\n",
        "matrix = pd.merge(matrix, group, on = [\"date_block_num\"], how = \"left\")\n",
        "matrix.date_avg_item_cnt = matrix[\"date_avg_item_cnt\"].astype(np.float16)\n",
        "matrix = lag_feature( matrix, [1], [\"date_avg_item_cnt\"] )\n",
        "matrix.drop( [\"date_avg_item_cnt\"], axis = 1, inplace = True )\n",
        "time.time() - ts\n",
        "\n",
        "\n",
        "#Add lag values for item_cnt_month for every month / shop combination.\n",
        "ts = time.time()\n",
        "group = matrix.groupby(['date_block_num', 'item_id']).agg({'item_cnt_month': ['mean']})\n",
        "group.columns = [ 'date_item_avg_item_cnt' ]\n",
        "group.reset_index(inplace=True)\n",
        "\n",
        "matrix = pd.merge(matrix, group, on=['date_block_num','item_id'], how='left')\n",
        "matrix.date_item_avg_item_cnt = matrix['date_item_avg_item_cnt'].astype(np.float16)\n",
        "matrix = lag_feature(matrix, [1,2,3], ['date_item_avg_item_cnt'])\n",
        "matrix.drop(['date_item_avg_item_cnt'], axis=1, inplace=True)\n",
        "time.time() - ts\n",
        "\n",
        "#Add lag values for item_cnt_month for month/shop/item.\n",
        "ts = time.time()\n",
        "group = matrix.groupby( [\"date_block_num\",\"shop_id\"] ).agg({\"item_cnt_month\" : [\"mean\"]})\n",
        "group.columns = [\"date_shop_avg_item_cnt\"]\n",
        "group.reset_index(inplace = True)\n",
        "\n",
        "matrix = pd.merge(matrix, group, on = [\"date_block_num\",\"shop_id\"], how = \"left\")\n",
        "matrix.date_avg_item_cnt = matrix[\"date_shop_avg_item_cnt\"].astype(np.float16)\n",
        "matrix = lag_feature( matrix, [1,2,3], [\"date_shop_avg_item_cnt\"] )\n",
        "matrix.drop( [\"date_shop_avg_item_cnt\"], axis = 1, inplace = True )\n",
        "time.time() - ts\n",
        "\n",
        "ts = time.time()\n",
        "group = matrix.groupby( [\"date_block_num\",\"shop_id\",\"item_id\"] ).agg({\"item_cnt_month\" : [\"mean\"]})\n",
        "group.columns = [\"date_shop_item_avg_item_cnt\"]\n",
        "group.reset_index(inplace = True)\n",
        "\n",
        "matrix = pd.merge(matrix, group, on = [\"date_block_num\",\"shop_id\",\"item_id\"], how = \"left\")\n",
        "matrix.date_avg_item_cnt = matrix[\"date_shop_item_avg_item_cnt\"].astype(np.float16)\n",
        "matrix = lag_feature( matrix, [1,2,3], [\"date_shop_item_avg_item_cnt\"] )\n",
        "matrix.drop( [\"date_shop_item_avg_item_cnt\"], axis = 1, inplace = True )\n",
        "time.time() - ts\n",
        "\n",
        "\n",
        "ts = time.time()\n",
        "group = matrix.groupby(['date_block_num', 'shop_id', 'subtype_code']).agg({'item_cnt_month': ['mean']})\n",
        "group.columns = ['date_shop_subtype_avg_item_cnt']\n",
        "group.reset_index(inplace=True)\n",
        "\n",
        "#Add lag values for item_cnt_month for month/shop/item subtype.\n",
        "matrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'subtype_code'], how='left')\n",
        "matrix.date_shop_subtype_avg_item_cnt = matrix['date_shop_subtype_avg_item_cnt'].astype(np.float16)\n",
        "matrix = lag_feature(matrix, [1], ['date_shop_subtype_avg_item_cnt'])\n",
        "matrix.drop(['date_shop_subtype_avg_item_cnt'], axis=1, inplace=True)\n",
        "time.time() - ts\n",
        "\n",
        "\n",
        "#Add lag values for item_cnt_month for month/city.\n",
        "ts = time.time()\n",
        "group = matrix.groupby(['date_block_num', 'shop_city']).agg({'item_cnt_month': ['mean']})\n",
        "group.columns = ['date_city_avg_item_cnt']\n",
        "group.reset_index(inplace=True)\n",
        "\n",
        "matrix = pd.merge(matrix, group, on=['date_block_num', \"shop_city\"], how='left')\n",
        "matrix.date_city_avg_item_cnt = matrix['date_city_avg_item_cnt'].astype(np.float16)\n",
        "matrix = lag_feature(matrix, [1], ['date_city_avg_item_cnt'])\n",
        "matrix.drop(['date_city_avg_item_cnt'], axis=1, inplace=True)\n",
        "time.time() - ts\n",
        "\n",
        "\n",
        "#Add lag values for item_cnt_month for month/city/item.\n",
        "ts = time.time()\n",
        "group = matrix.groupby(['date_block_num', 'item_id', 'shop_city']).agg({'item_cnt_month': ['mean']})\n",
        "group.columns = [ 'date_item_city_avg_item_cnt' ]\n",
        "group.reset_index(inplace=True)\n",
        "\n",
        "matrix = pd.merge(matrix, group, on=['date_block_num', 'item_id', 'shop_city'], how='left')\n",
        "matrix.date_item_city_avg_item_cnt = matrix['date_item_city_avg_item_cnt'].astype(np.float16)\n",
        "matrix = lag_feature(matrix, [1], ['date_item_city_avg_item_cnt'])\n",
        "matrix.drop(['date_item_city_avg_item_cnt'], axis=1, inplace=True)\n",
        "time.time() - ts\n",
        "\n",
        "#Add average item price on to matrix df.\n",
        "#Add lag values of item price per month.\n",
        "#Add delta price values - how current month average pirce relates to global average.\n",
        "\n",
        "ts = time.time()\n",
        "group = train.groupby( [\"item_id\"] ).agg({\"item_price\": [\"mean\"]})\n",
        "group.columns = [\"item_avg_item_price\"]\n",
        "group.reset_index(inplace = True)\n",
        "\n",
        "matrix = matrix.merge( group, on = [\"item_id\"], how = \"left\" )\n",
        "matrix[\"item_avg_item_price\"] = matrix.item_avg_item_price.astype(np.float16)\n",
        "\n",
        "group = train.groupby( [\"date_block_num\",\"item_id\"] ).agg( {\"item_price\": [\"mean\"]} )\n",
        "group.columns = [\"date_item_avg_item_price\"]\n",
        "group.reset_index(inplace = True)\n",
        "\n",
        "matrix = matrix.merge(group, on = [\"date_block_num\",\"item_id\"], how = \"left\")\n",
        "matrix[\"date_item_avg_item_price\"] = matrix.date_item_avg_item_price.astype(np.float16)\n",
        "lags = [1, 2, 3]\n",
        "matrix = lag_feature( matrix, lags, [\"date_item_avg_item_price\"] )\n",
        "for i in lags:\n",
        "  matrix[\"delta_price_lag_\" + str(i) ] = (matrix[\"date_item_avg_item_price_lag_\" + str(i)]- matrix[\"item_avg_item_price\"] )/ matrix[\"item_avg_item_price\"]\n",
        "\n",
        "def select_trends(row) :\n",
        "  for i in lags:\n",
        "      if row[\"delta_price_lag_\" + str(i)]:\n",
        "          return row[\"delta_price_lag_\" + str(i)]\n",
        "  return 0\n",
        "\n",
        "matrix[\"delta_price_lag\"] = matrix.apply(select_trends, axis = 1)\n",
        "matrix[\"delta_price_lag\"] = matrix.delta_price_lag.astype( np.float16 )\n",
        "matrix[\"delta_price_lag\"].fillna( 0 ,inplace = True)\n",
        "\n",
        "features_to_drop = [\"item_avg_item_price\", \"date_item_avg_item_price\"]\n",
        "for i in lags:\n",
        "  features_to_drop.append(\"date_item_avg_item_price_lag_\" + str(i) )\n",
        "  features_to_drop.append(\"delta_price_lag_\" + str(i) )\n",
        "\n",
        "matrix.drop(features_to_drop, axis = 1, inplace = True)\n",
        "time.time() - ts\n",
        "\n",
        "#Add total shop revenue per month to matrix df.\n",
        "#Add lag values of revenue per month.\n",
        "#Add delta revenue values - how current month revenue relates to global average.\n",
        "\n",
        "ts = time.time()\n",
        "group = train.groupby( [\"date_block_num\",\"shop_id\"] ).agg({\"revenue\": [\"sum\"] })\n",
        "group.columns = [\"date_shop_revenue\"]\n",
        "group.reset_index(inplace = True)\n",
        "\n",
        "matrix = matrix.merge( group , on = [\"date_block_num\", \"shop_id\"], how = \"left\" )\n",
        "matrix['date_shop_revenue'] = matrix['date_shop_revenue'].astype(np.float32)\n",
        "\n",
        "group = group.groupby([\"shop_id\"]).agg({ \"date_block_num\":[\"mean\"] })\n",
        "group.columns = [\"shop_avg_revenue\"]\n",
        "group.reset_index(inplace = True )\n",
        "\n",
        "matrix = matrix.merge( group, on = [\"shop_id\"], how = \"left\" )\n",
        "matrix[\"shop_avg_revenue\"] = matrix.shop_avg_revenue.astype(np.float32)\n",
        "matrix[\"delta_revenue\"] = (matrix['date_shop_revenue'] - matrix['shop_avg_revenue']) / matrix['shop_avg_revenue']\n",
        "matrix[\"delta_revenue\"] = matrix[\"delta_revenue\"]. astype(np.float32)\n",
        "\n",
        "matrix = lag_feature(matrix, [1], [\"delta_revenue\"])\n",
        "matrix[\"delta_revenue_lag_1\"] = matrix[\"delta_revenue_lag_1\"].astype(np.float32)\n",
        "matrix.drop( [\"date_shop_revenue\", \"shop_avg_revenue\", \"delta_revenue\"] ,axis = 1, inplace = True)\n",
        "time.time() - ts\n",
        "\n",
        "#Add month and number of days in each month to matrix df.\n",
        "matrix[\"month\"] = matrix[\"date_block_num\"] % 12\n",
        "days = pd.Series([31,28,31,30,31,30,31,31,30,31,30,31])\n",
        "matrix[\"days\"] = matrix[\"month\"].map(days).astype(np.int8)\n",
        "\n",
        "ts = time.time()\n",
        "matrix[\"item_shop_first_sale\"] = matrix[\"date_block_num\"] - matrix.groupby([\"item_id\",\"shop_id\"])[\"date_block_num\"].transform('min')\n",
        "matrix[\"item_first_sale\"] = matrix[\"date_block_num\"] - matrix.groupby([\"item_id\"])[\"date_block_num\"].transform('min')\n",
        "time.time() - ts\n",
        "\n",
        "ts = time.time()\n",
        "matrix = matrix[matrix[\"date_block_num\"] > 3]\n",
        "time.time() - ts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koRP1pT2NOBl"
      },
      "outputs": [],
      "source": [
        "#need to cast it again as 32 to perform ffill()\n",
        "matrix = matrix.astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQf7-hAgNOgF"
      },
      "outputs": [],
      "source": [
        "matrix.ffill(axis = 0, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPm7FO0tBD7d"
      },
      "outputs": [],
      "source": [
        "#matrix.ffill().add(matrix.bfill()).div(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKrnW0E-PmBU"
      },
      "outputs": [],
      "source": [
        "data = matrix.copy()\n",
        "del matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35za6B4kPfnR"
      },
      "outputs": [],
      "source": [
        "X_train = data[data.date_block_num < 33].drop(['item_cnt_month'], axis=1)\n",
        "Y_train = data[data.date_block_num < 33]['item_cnt_month']\n",
        "X_valid = data[data.date_block_num == 33].drop(['item_cnt_month'], axis=1)\n",
        "Y_valid = data[data.date_block_num == 33]['item_cnt_month']\n",
        "X_test = data[data.date_block_num == 34].drop(['item_cnt_month'], axis=1)\n",
        "\n",
        "Y_train = Y_train.clip(0, 20)\n",
        "Y_valid = Y_valid.clip(0, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-ESnfyOZ8_V"
      },
      "source": [
        "# MLP approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgKZGsVxaO_-"
      },
      "outputs": [],
      "source": [
        "def earlystop(monitor = 'loss', mode = 'min', patience = 5, restore_best_weights = True, verbose = 1):\n",
        "  es = EarlyStopping(monitor = monitor, mode = mode, patience = patience,restore_best_weights = restore_best_weights, verbose=verbose)\n",
        "  return es\n",
        "  \n",
        "epochs = 10\n",
        "batch = 64\n",
        "lr = 0.001\n",
        "adam = Adam(lr)\n",
        "es = earlystop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKD4gqMvZ_pi"
      },
      "outputs": [],
      "source": [
        "model_mlp = Sequential()\n",
        "model_mlp.add(Dense(50, activation='relu', input_dim=X_train.shape[1]))\n",
        "model_mlp.add(Dense(1))\n",
        "model_mlp.compile(loss='mse', optimizer=adam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIQLrjQSaUlO",
        "outputId": "ff046dbb-22f3-48ff-f4b8-5b88ee0f682c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 50)                1650      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,701\n",
            "Trainable params: 1,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_mlp.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwOKsNwmZ_r7",
        "outputId": "3c53dcc4-8c35-4e04-8123-aec05d9a4937"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "286818/286818 [==============================] - 730s 3ms/step - loss: 3884.8613 - val_loss: 2.3832\n",
            "Epoch 2/10\n",
            "286818/286818 [==============================] - 715s 2ms/step - loss: 30.3831 - val_loss: 1.2930\n",
            "Epoch 3/10\n",
            "286818/286818 [==============================] - 717s 3ms/step - loss: 1.4801 - val_loss: 1.2933\n",
            "Epoch 4/10\n",
            "286818/286818 [==============================] - 717s 3ms/step - loss: 1.4801 - val_loss: 1.2945\n",
            "Epoch 5/10\n",
            "286818/286818 [==============================] - 719s 3ms/step - loss: 1.4801 - val_loss: 1.2957\n",
            "Epoch 6/10\n",
            "286818/286818 [==============================] - 719s 3ms/step - loss: 1.4801 - val_loss: 1.2946\n",
            "Epoch 7/10\n",
            "286818/286818 [==============================] - 716s 2ms/step - loss: 1.4801 - val_loss: 1.2947\n",
            "Epoch 8/10\n",
            "286818/286818 [==============================] - 727s 3ms/step - loss: 1.4801 - val_loss: 1.2945\n",
            "Epoch 9/10\n",
            "286818/286818 [==============================] - 733s 3ms/step - loss: 1.4801 - val_loss: 1.2938\n",
            "Epoch 10/10\n",
            "286818/286818 [==============================] - 733s 3ms/step - loss: 1.4801 - val_loss: 1.2950\n"
          ]
        }
      ],
      "source": [
        "mlp_history = model_mlp.fit(X_train, Y_train, validation_data = (X_valid, Y_valid), epochs=epochs, callbacks=[es], verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKaq7TWzt0mp"
      },
      "outputs": [],
      "source": [
        "df_his = pd.DataFrame(mlp_history.history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwPtX6YPt0my"
      },
      "outputs": [],
      "source": [
        "predicted_test_data = model_mlp.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sd0oVgykt0my"
      },
      "outputs": [],
      "source": [
        "submission['item_cnt_month'] = predicted_test_data.clip(0,20).round(0)\n",
        "submission.to_csv('submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJNuFtkft0my",
        "outputId": "74a9c53d-3f13-4ec5-8829-588e0f3be8c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100% 2.14M/2.14M [00:01<00:00, 1.41MB/s]\n",
            "Successfully submitted to Predict Future Sales"
          ]
        }
      ],
      "source": [
        "!kaggle competitions submit -c competitive-data-science-predict-future-sales -f submission.csv -m \"mlp_features_engineered\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf3G_ZkjNqut"
      },
      "source": [
        "# CNN + LSTM approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lnX4f4GNnz7"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([\n",
        "  keras.layers.Conv1D(filters=32, kernel_size=3,\n",
        "                      strides=1, padding=\"causal\",\n",
        "                      activation=\"relu\",\n",
        "                      input_shape=[None, 1]),\n",
        "  keras.layers.LSTM(32, return_sequences=True, input_shape = (X_train.shape[1], 1), dropout = 0.2),\n",
        "  keras.layers.LSTM(32, return_sequences=True, input_shape = (X_train.shape[1], 1), dropout = 0.2),\n",
        "  keras.layers.LSTM(32, return_sequences=False, dropout = 0.3),\n",
        "  keras.layers.Dense(35),\n",
        "  keras.layers.Dense(10),\n",
        "  keras.layers.Dense(1),\n",
        "  #keras.layers.Lambda(lambda x: x * 200)\n",
        "])\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss=keras.losses.Huber(), optimizer=optimizer, metrics = ['mse'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jeVjswtUIdy"
      },
      "outputs": [],
      "source": [
        "def earlystop(monitor = 'loss', mode = 'min', patience = 5, restore_best_weights = True, verbose = 1):\n",
        "  es = EarlyStopping(monitor = monitor, mode = mode, patience = patience,restore_best_weights = restore_best_weights, verbose=verbose)\n",
        "  return es\n",
        "  \n",
        "es = earlystop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTHSOCxtTcJO",
        "outputId": "11507682-adac-439b-cf92-581b096585bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, None, 32)          128       \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, None, 32)          8320      \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, None, 32)          8320      \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 32)                8320      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 35)                1155      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                360       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,614\n",
            "Trainable params: 26,614\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid"
      ],
      "metadata": {
        "id": "e3kbsNln8QIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8UY0djAOuuX",
        "outputId": "89b8902b-9ada-41af-cd2f-afefed86dc97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "6275/6275 [==============================] - 155s 25ms/step - loss: 8.6662e-04 - mse: 0.0023 - val_loss: 0.0123 - val_mse: 0.0431\n",
            "Epoch 2/50\n",
            "6275/6275 [==============================] - 158s 25ms/step - loss: 7.9433e-04 - mse: 0.0023 - val_loss: 0.0120 - val_mse: 0.0366\n",
            "Epoch 3/50\n",
            "6275/6275 [==============================] - 156s 25ms/step - loss: 5.0009e-04 - mse: 0.0011 - val_loss: 0.0093 - val_mse: 0.0285\n",
            "Epoch 4/50\n",
            "6275/6275 [==============================] - 159s 25ms/step - loss: 4.7705e-04 - mse: 0.0011 - val_loss: 0.0121 - val_mse: 0.0376\n",
            "Epoch 5/50\n",
            "6275/6275 [==============================] - 154s 25ms/step - loss: 4.1141e-04 - mse: 9.8904e-04 - val_loss: 0.0148 - val_mse: 0.0416\n",
            "Epoch 6/50\n",
            "6275/6275 [==============================] - 160s 25ms/step - loss: 3.9778e-04 - mse: 0.0010 - val_loss: 0.0097 - val_mse: 0.0299\n",
            "Epoch 7/50\n",
            "6275/6275 [==============================] - 155s 25ms/step - loss: 4.7090e-04 - mse: 0.0012 - val_loss: 0.0123 - val_mse: 0.0372\n",
            "Epoch 8/50\n",
            "6275/6275 [==============================] - 159s 25ms/step - loss: 4.2707e-04 - mse: 0.0018 - val_loss: 0.0105 - val_mse: 0.0328\n",
            "Epoch 9/50\n",
            "6275/6275 [==============================] - 153s 24ms/step - loss: 3.4090e-04 - mse: 8.8457e-04 - val_loss: 0.0114 - val_mse: 0.0353\n",
            "Epoch 10/50\n",
            "6275/6275 [==============================] - 161s 26ms/step - loss: 3.4442e-04 - mse: 0.0010 - val_loss: 0.0093 - val_mse: 0.0246\n",
            "Epoch 11/50\n",
            "6275/6275 [==============================] - 155s 25ms/step - loss: 3.1841e-04 - mse: 8.5453e-04 - val_loss: 0.0105 - val_mse: 0.0324\n",
            "Epoch 12/50\n",
            "6275/6275 [==============================] - 161s 26ms/step - loss: 3.7850e-04 - mse: 0.0011 - val_loss: 0.0103 - val_mse: 0.0319\n",
            "Epoch 13/50\n",
            "6275/6275 [==============================] - 154s 25ms/step - loss: 3.2371e-04 - mse: 9.1313e-04 - val_loss: 0.0113 - val_mse: 0.0327\n",
            "Epoch 14/50\n",
            "6275/6275 [==============================] - 160s 26ms/step - loss: 3.2163e-04 - mse: 8.3802e-04 - val_loss: 0.0122 - val_mse: 0.0365\n",
            "Epoch 15/50\n",
            "6275/6275 [==============================] - 155s 25ms/step - loss: 3.0948e-04 - mse: 9.3839e-04 - val_loss: 0.0123 - val_mse: 0.0356\n",
            "Epoch 16/50\n",
            "6275/6275 [==============================] - 158s 25ms/step - loss: 2.4464e-04 - mse: 7.6371e-04 - val_loss: 0.0142 - val_mse: 0.0468\n",
            "Epoch 17/50\n",
            "6275/6275 [==============================] - 155s 25ms/step - loss: 3.3293e-04 - mse: 9.0761e-04 - val_loss: 0.0095 - val_mse: 0.0267\n",
            "Epoch 18/50\n",
            "6275/6275 [==============================] - 157s 25ms/step - loss: 2.1592e-04 - mse: 5.4767e-04 - val_loss: 0.0121 - val_mse: 0.0342\n",
            "Epoch 19/50\n",
            "6275/6275 [==============================] - 157s 25ms/step - loss: 2.5307e-04 - mse: 7.3922e-04 - val_loss: 0.0108 - val_mse: 0.0330\n",
            "Epoch 20/50\n",
            "6275/6275 [==============================] - 156s 25ms/step - loss: 2.4198e-04 - mse: 6.7692e-04 - val_loss: 0.0115 - val_mse: 0.0352\n",
            "Epoch 21/50\n",
            "6275/6275 [==============================] - 157s 25ms/step - loss: 2.1169e-04 - mse: 5.7372e-04 - val_loss: 0.0104 - val_mse: 0.0301\n",
            "Epoch 22/50\n",
            "6275/6275 [==============================] - 158s 25ms/step - loss: 2.3470e-04 - mse: 6.8587e-04 - val_loss: 0.0090 - val_mse: 0.0255\n",
            "Epoch 23/50\n",
            "6275/6275 [==============================] - 158s 25ms/step - loss: 3.6523e-04 - mse: 0.0016 - val_loss: 0.0124 - val_mse: 0.0372\n",
            "Epoch 24/50\n",
            "6275/6275 [==============================] - 154s 25ms/step - loss: 2.7557e-04 - mse: 7.7752e-04 - val_loss: 0.0102 - val_mse: 0.0333\n",
            "Epoch 25/50\n",
            "6275/6275 [==============================] - 159s 25ms/step - loss: 2.4893e-04 - mse: 6.9574e-04 - val_loss: 0.0112 - val_mse: 0.0376\n",
            "Epoch 26/50\n",
            "6274/6275 [============================>.] - ETA: 0s - loss: 3.1388e-04 - mse: 9.4346e-04Restoring model weights from the end of the best epoch: 21.\n",
            "6275/6275 [==============================] - 154s 25ms/step - loss: 3.1386e-04 - mse: 9.4340e-04 - val_loss: 0.0093 - val_mse: 0.0286\n",
            "Epoch 26: early stopping\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, Y_train, validation_data=(X_valid, Y_valid), epochs = 50, batch_size = 1024, verbose = 1, callbacks = [es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-ezg7y-Uj0O"
      },
      "outputs": [],
      "source": [
        "df_his = pd.DataFrame(history.history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vt80dGIDY3aU"
      },
      "outputs": [],
      "source": [
        "predicted_test_data = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8xDIPBorsz1"
      },
      "outputs": [],
      "source": [
        "submission['item_cnt_month'] = predicted_test_data.clip(0,20).round(0)\n",
        "submission.to_csv('submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irqxfyu1rsz1"
      },
      "outputs": [],
      "source": [
        "!kaggle competitions submit -c competitive-data-science-predict-future-sales -f submission.csv -m \"CNN + LSTM with feature engineering\""
      ]
    }
  ]
}